import { serve } from 'https://deno.land/std@0.192.0/http/server.ts'
import Parser from 'https://esm.sh/rss-parser@3.13.0'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const parser = new Parser({
  customFields: {
    item: [
      ['media:content', 'media:content'],
      ['media:thumbnail', 'media:thumbnail'],
      ['enclosure', 'enclosure'],
    ],
  },
})

serve(async () => {
  try {
    const SUPABASE_URL = Deno.env.get('SUPABASE_URL')
    const SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    const ANTHROPIC_API_KEY = Deno.env.get('ANTHROPIC_API_KEY')

    if (!SUPABASE_URL || !SERVICE_ROLE_KEY) {
      throw new Error('Supabase env missing')
    }

    const supabase = createClient(SUPABASE_URL, SERVICE_ROLE_KEY)

    console.log('âœ… Starting news sync...')

    // lists ë¡œë“œ
    const { data: lists } = await supabase.from('lists').select('list_id, name')

    console.log('ğŸ“‹ Lists loaded:', lists?.length)

    const listMap = new Map<string, string>()
    lists?.forEach((l) => {
      listMap.set(l.name, l.list_id)
      console.log(`  - ${l.name} -> ${l.list_id}`)
    })

    const results = {
      korean_tech: { inserted: 0, skipped: 0, no_category: 0 },
      naver: { inserted: 0, skipped: 0, no_category: 0 },
    }

    // í•œêµ­ IT ë‰´ìŠ¤ ìˆ˜ì§‘
    try {
      const result = await syncKoreanTech(supabase, listMap, ANTHROPIC_API_KEY)
      results.korean_tech = result
    } catch (e) {
      console.error('Korean tech sync failed:', e)
    }

    // Naver ìˆ˜ì§‘
    try {
      const result = await syncNaverNews(supabase, listMap, ANTHROPIC_API_KEY)
      results.naver = result
    } catch (e) {
      console.error('Naver sync failed:', e)
    }

    return new Response(
      JSON.stringify({
        ok: true,
        timestamp: new Date().toISOString(),
        ...results,
      }),
      {
        headers: { 'Content-Type': 'application/json' },
      }
    )
  } catch (e) {
    console.error('SYNC ERROR:', e)
    return new Response(JSON.stringify({ error: String(e) }), { status: 500 })
  }
})

async function syncKoreanTech(
  supabase: any,
  listMap: Map<string, string>,
  anthropicKey?: string
) {
  console.log('ğŸ‡°ğŸ‡· Starting Korean Tech News sync...')

  const rssSources = [
    { name: 'ITWorld', url: 'https://www.itworld.co.kr/rss/news.xml' },
    { name: 'ZDNet', url: 'https://feeds.feedburner.com/zdkorea' },
    { name: 'Boannews', url: 'https://www.boannews.com/media/news_rss.xml' },
  ]

  let totalInserted = 0
  let totalSkipped = 0
  let totalNoCategory = 0

  for (const source of rssSources) {
    try {
      console.log(`ğŸ“¡ Fetching ${source.name}...`)

      const rssRes = await fetch(source.url, {
        headers: {
          'User-Agent':
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
          'Accept-Charset': 'utf-8',
        },
      })

      if (!rssRes.ok) {
        console.error(`âŒ ${source.name} HTTP ${rssRes.status}`)
        continue
      }

      // ì¸ì½”ë”© ê°ì§€ ë° ë””ì½”ë”©
      const buffer = await rssRes.arrayBuffer()
      let text = ''

      // UTF-8 ì‹œë„
      try {
        const decoder = new TextDecoder('utf-8', { fatal: true })
        text = decoder.decode(buffer)
      } catch {
        // UTF-8 ì‹¤íŒ¨ì‹œ EUC-KR ì‹œë„
        try {
          const decoder = new TextDecoder('euc-kr')
          text = decoder.decode(buffer)
          console.log(`ğŸ“ ${source.name}: Using EUC-KR encoding`)
        } catch {
          // ë‘˜ ë‹¤ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë””ì½”ë”©
          const decoder = new TextDecoder()
          text = decoder.decode(buffer)
          console.log(`ğŸ“ ${source.name}: Using default encoding`)
        }
      }
      console.log(`ğŸ“¥ ${source.name}: ${text.length} bytes`)

      const feed = await parser.parseString(text)
      const items = feed.items.slice(0, 20)

      console.log(`ğŸ“° ${source.name}: ${items.length} items`)

      let inserted = 0
      let skipped = 0
      let noCategory = 0

      for (const item of items) {
        if (!item.title || !item.link) continue

        // ğŸ“… ë‚ ì§œ ë””ë²„ê¹…
        console.log('ğŸ“… Date fields:', {
          pubDate: item.pubDate,
          isoDate: item.isoDate,
          date: item.date,
          published: item.published,
        })

        // ì¤‘ë³µ ì²´í¬
        const { data: exists } = await supabase
          .from('articles')
          .select('article_id')
          .eq('link', item.link)
          .maybeSingle()

        if (exists) {
          skipped++
          continue
        }

        // ğŸ“… ë‚ ì§œ íŒŒì‹± (ì—¬ëŸ¬ í•„ë“œ ì‹œë„)
        const publishedAt =
          item.pubDate || item.isoDate || item.date || item.published
        const publishedAtISO = publishedAt
          ? new Date(publishedAt).toISOString()
          : null

        // ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ
        const imageUrl = extractImageUrl(item)

        // ğŸ¤– AIë¡œ ì¹´í…Œê³ ë¦¬ + í‚¤ì›Œë“œ ë¶„ì„
        let category = null
        let keywords: string[] = []

        if (anthropicKey) {
          try {
            const aiResult = await analyzeWithAI(
              item.title,
              item.contentSnippet || '',
              anthropicKey,
              Array.from(listMap.keys())
            )
            category = aiResult.category
            keywords = aiResult.keywords
            console.log(`ğŸ¤– AI: [${category}] ${keywords.join(', ')}`)
          } catch (e) {
            console.error(
              'AI analysis failed, fallback to keyword matching:',
              e
            )
            category = classify(item.title + ' ' + (item.contentSnippet || ''))
            keywords = extractKeywords(
              item.title + ' ' + (item.contentSnippet || '')
            )
          }
        } else {
          // AI ì—†ìœ¼ë©´ ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­ + ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ
          category = classify(item.title + ' ' + (item.contentSnippet || ''))
          keywords = extractKeywords(
            item.title + ' ' + (item.contentSnippet || '')
          )
          console.log(`ğŸ” Keywords: ${keywords.join(', ')}`)
        }

        // ì¹´í…Œê³ ë¦¬ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if (!category) {
          noCategory++
          console.log(`â­ï¸  No category: ${item.title.substring(0, 40)}...`)
          continue
        }

        const listId = listMap.get(category)

        // listId ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if (!listId) {
          noCategory++
          console.log(
            `â­ï¸  Category not found in DB: [${category}] ${item.title.substring(0, 40)}...`
          )
          continue
        }

        const { error } = await supabase.from('articles').insert({
          title: item.title,
          link: item.link,
          summary: item.contentSnippet ?? null,
          list: listId,
          source: source.name.toLowerCase(),
          published_at: publishedAtISO,
          image_url: imageUrl,
          keywords: keywords.length > 0 ? keywords : null,
        })

        if (error) {
          console.error(`âŒ Insert error:`, error.message)
        } else {
          console.log(
            `âœ… [${category}] ${item.title.substring(0, 40)}... | ğŸ–¼ï¸ ${imageUrl ? 'Y' : 'N'} | ğŸ“… ${publishedAtISO || 'NO_DATE'}`
          )
          inserted++
        }
      }

      console.log(
        `âœ… ${source.name}: +${inserted}, skip ${skipped}, no_cat ${noCategory}`
      )
      totalInserted += inserted
      totalSkipped += skipped
      totalNoCategory += noCategory
    } catch (e) {
      console.error(`âŒ ${source.name} error:`, e)
    }
  }

  return {
    inserted: totalInserted,
    skipped: totalSkipped,
    no_category: totalNoCategory,
  }
}

async function syncNaverNews(
  supabase: any,
  listMap: Map<string, string>,
  anthropicKey?: string
) {
  console.log('ğŸ“° Starting Naver News sync...')

  const rssUrl = 'https://news.naver.com/rss/main_section.xml?sid1=105'

  let inserted = 0
  let skipped = 0
  let noCategory = 0

  try {
    const rssRes = await fetch(rssUrl, {
      headers: {
        'User-Agent':
          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept-Charset': 'utf-8',
      },
    })

    if (!rssRes.ok) {
      console.error(`âŒ Naver HTTP ${rssRes.status}`)
      return { inserted, skipped, no_category: noCategory }
    }

    // ì¸ì½”ë”© ê°ì§€ ë° ë””ì½”ë”©
    const buffer = await rssRes.arrayBuffer()
    let text = ''

    // UTF-8 ì‹œë„
    try {
      const decoder = new TextDecoder('utf-8', { fatal: true })
      text = decoder.decode(buffer)
    } catch {
      // UTF-8 ì‹¤íŒ¨ì‹œ EUC-KR ì‹œë„
      try {
        const decoder = new TextDecoder('euc-kr')
        text = decoder.decode(buffer)
        console.log('ğŸ“ Naver: Using EUC-KR encoding')
      } catch {
        // ë‘˜ ë‹¤ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë””ì½”ë”©
        const decoder = new TextDecoder()
        text = decoder.decode(buffer)
        console.log('ğŸ“ Naver: Using default encoding')
      }
    }
    console.log(`ğŸ“¥ Naver: ${text.length} bytes`)

    const feed = await parser.parseString(text)
    const items = feed.items.slice(0, 20)

    console.log(`ğŸ“° Naver: ${items.length} items`)

    for (const item of items) {
      if (!item.title || !item.link) continue

      // ì¤‘ë³µ ì²´í¬
      const { data: exists } = await supabase
        .from('articles')
        .select('article_id')
        .eq('link', item.link)
        .maybeSingle()

      if (exists) {
        skipped++
        continue
      }

      // ğŸ“… ë‚ ì§œ íŒŒì‹±
      const publishedAt = item.pubDate
        ? new Date(item.pubDate).toISOString()
        : null

      // ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ
      const imageUrl = extractImageUrl(item)

      // ğŸ¤– AIë¡œ ì¹´í…Œê³ ë¦¬ + í‚¤ì›Œë“œ ë¶„ì„
      let category = null
      let keywords: string[] = []

      if (anthropicKey) {
        try {
          const aiResult = await analyzeWithAI(
            item.title,
            item.contentSnippet || '',
            anthropicKey,
            Array.from(listMap.keys())
          )
          category = aiResult.category
          keywords = aiResult.keywords
          console.log(`ğŸ¤– AI: [${category}] ${keywords.join(', ')}`)
        } catch (e) {
          console.error('AI analysis failed, fallback to keyword matching:', e)
          category = classify(item.title + ' ' + (item.contentSnippet || ''))
        }
      } else {
        // AI ì—†ìœ¼ë©´ ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­
        category = classify(item.title + ' ' + (item.contentSnippet || ''))
      }

      // ì¹´í…Œê³ ë¦¬ ì—†ìœ¼ë©´ ìŠ¤í‚µ
      if (!category) {
        noCategory++
        console.log(`â­ï¸  No category: ${item.title.substring(0, 40)}...`)
        continue
      }

      const listId = listMap.get(category)

      // listId ì—†ìœ¼ë©´ ìŠ¤í‚µ
      if (!listId) {
        noCategory++
        console.log(
          `â­ï¸  Category not found in DB: [${category}] ${item.title.substring(0, 40)}...`
        )
        continue
      }

      const { error } = await supabase.from('articles').insert({
        title: item.title,
        link: item.link,
        summary: item.contentSnippet ?? null,
        list: listId,
        source: 'naver',
        published_at: publishedAt,
        image_url: imageUrl,
        keywords: keywords.length > 0 ? keywords : null,
      })

      if (error) {
        console.error(`âŒ Insert error:`, error.message)
      } else {
        console.log(
          `âœ… [${category}] ${item.title.substring(0, 40)}... | ğŸ–¼ï¸ ${imageUrl ? 'Y' : 'N'} | ğŸ“… ${publishedAt}`
        )
        inserted++
      }
    }

    console.log(`âœ… Naver: +${inserted}, skip ${skipped}, no_cat ${noCategory}`)
  } catch (e) {
    console.error('âŒ Naver error:', e)
  }

  return { inserted, skipped, no_category: noCategory }
}

function classify(text: string): string | null {
  const lowerText = text.toLowerCase()

  // DB lists í…Œì´ë¸”ì˜ ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜
  const categories = {
    Frontend: [
      'react',
      'vue',
      'angular',
      'svelte',
      'next.js',
      'nuxt',
      'typescript',
      'javascript',
      'css',
      'html',
      'tailwind',
      'frontend',
      'ui component',
      'jsx',
      'tsx',
      'webpack',
      'vite',
      'í”„ë¡ íŠ¸ì—”ë“œ',
    ],
    Backend: [
      'node',
      'express',
      'nestjs',
      'django',
      'flask',
      'fastapi',
      'spring',
      'backend',
      'api',
      'restful',
      'graphql',
      'database',
      'postgresql',
      'mysql',
      'mongodb',
      'redis',
      'orm',
      'ë°±ì—”ë“œ',
      'ë°ì´í„°ë² ì´ìŠ¤',
    ],
    AI: [
      'ai',
      'llm',
      'gpt',
      'claude',
      'gemini',
      'machine learning',
      'deep learning',
      'neural network',
      'transformer',
      'pytorch',
      'tensorflow',
      'chatbot',
      'openai',
      'anthropic',
      'ì¸ê³µì§€ëŠ¥',
      'ë¨¸ì‹ ëŸ¬ë‹',
      'ë”¥ëŸ¬ë‹',
    ],
    Infrastructure: [
      'kubernetes',
      'docker',
      'container',
      'devops',
      'ci/cd',
      'jenkins',
      'github actions',
      'terraform',
      'ansible',
      'nginx',
      'apache',
      'ì¸í”„ë¼',
      'k8s',
    ],
    Cloud: [
      'aws',
      'azure',
      'gcp',
      'google cloud',
      'cloud',
      's3',
      'lambda',
      'ec2',
      'cloudflare',
      'serverless',
      'vercel',
      'netlify',
      'í´ë¼ìš°ë“œ',
    ],
    Security: [
      'security',
      'auth',
      'authentication',
      'jwt',
      'oauth',
      'encryption',
      'ssl',
      'tls',
      'vulnerability',
      'hack',
      'cyber',
      'penetration',
      'ë³´ì•ˆ',
      'ì·¨ì•½ì ',
      'í•´í‚¹',
    ],
    'Product Management': [
      'product',
      'pm',
      'product manager',
      'roadmap',
      'agile',
      'scrum',
      'jira',
      'planning',
      'strategy',
      'user story',
      'ê¸°íš',
      'í”„ë¡œë•íŠ¸',
      'í”„ë¡œì íŠ¸ ê´€ë¦¬',
    ],
    'UI/UX Design': [
      'design',
      'ui',
      'ux',
      'user experience',
      'user interface',
      'figma',
      'sketch',
      'prototype',
      'wireframe',
      'mockup',
      'ë””ìì¸',
      'ui/ux',
      'ì‚¬ìš©ì ê²½í—˜',
    ],
  }

  const scores: Record<string, number> = {}

  for (const [category, keywords] of Object.entries(categories)) {
    scores[category] = 0
    for (const keyword of keywords) {
      if (lowerText.includes(keyword.toLowerCase())) {
        scores[category]++
      }
    }
  }

  let maxScore = 0
  let bestCategory: string | null = null

  for (const [category, score] of Object.entries(scores)) {
    if (score > maxScore) {
      maxScore = score
      bestCategory = category
    }
  }

  // ìµœì†Œ 1ê°œ ì´ìƒ í‚¤ì›Œë“œ ë§¤ì¹­ë˜ì–´ì•¼ ë¶„ë¥˜
  return maxScore > 0 ? bestCategory : null
}

// ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ (RSS + Jina ë³¸ë¬¸)
async function extractImageUrl(item: any): Promise<string | null> {
  // 1ë‹¨ê³„: RSSì—ì„œ ë¨¼ì € ì°¾ê¸° (ë¹ ë¦„)
  if (item.enclosure?.url) {
    return item.enclosure.url
  }

  if (item['media:content']?.$?.url) {
    return item['media:content'].$.url
  }

  if (item['media:thumbnail']?.$?.url) {
    return item['media:thumbnail'].$.url
  }

  if (item.content) {
    const imgMatch = item.content.match(/<img[^>]+src="([^">]+)"/)
    if (imgMatch) return imgMatch[1]
  }

  // 2ë‹¨ê³„: RSSì— ì—†ìœ¼ë©´ Jinaë¡œ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ (ëŠë¦¼)
  if (item.link) {
    try {
      const jinaUrl = `https://r.jina.ai/${item.link}`
      const response = await fetch(jinaUrl, {
        headers: { 'X-Timeout': '5' }, // 5ì´ˆ íƒ€ì„ì•„ì›ƒ
      })

      if (response.ok) {
        const markdown = await response.text()
        // ë§ˆí¬ë‹¤ìš´ì—ì„œ ì²« ì´ë¯¸ì§€ ì°¾ê¸°
        const imgMatch = markdown.match(/!\[.*?\]\((https?:\/\/[^\)]+)\)/)
        if (imgMatch) {
          console.log(`ğŸ–¼ï¸  Jina found image: ${imgMatch[1]}`)
          return imgMatch[1]
        }
      }
    } catch (e) {
      console.error('Jina image fetch failed:', e)
    }
  }

  return null
}

// ğŸ” í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ (AI ì—†ì„ ë•Œ)
function extractKeywords(text: string): string[] {
  const keywords: string[] = []
  const lowerText = text.toLowerCase()

  // ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ
  const techKeywords = [
    'react',
    'vue',
    'angular',
    'typescript',
    'javascript',
    'python',
    'java',
    'node',
    'express',
    'django',
    'spring',
    'docker',
    'kubernetes',
    'aws',
    'azure',
    'gcp',
    'ai',
    'llm',
    'gpt',
    'claude',
    'openai',
    'security',
    'ë³´ì•ˆ',
    'ì·¨ì•½ì ',
    'í•´í‚¹',
    'api',
    'database',
    'ë°ì´í„°ë² ì´ìŠ¤',
    'cloud',
    'í´ë¼ìš°ë“œ',
    'ì¸ê³µì§€ëŠ¥',
    'ë¨¸ì‹ ëŸ¬ë‹',
    'devops',
    'frontend',
    'backend',
  ]

  for (const keyword of techKeywords) {
    if (lowerText.includes(keyword)) {
      keywords.push(keyword)
    }
  }

  return keywords.slice(0, 5) // ìµœëŒ€ 5ê°œ
}

// ğŸ¤– AIë¡œ ì¹´í…Œê³ ë¦¬ + í‚¤ì›Œë“œ ë¶„ì„
async function analyzeWithAI(
  title: string,
  summary: string,
  apiKey: string,
  availableCategories: string[]
): Promise<{ category: string | null; keywords: string[] }> {
  if (!apiKey) {
    return { category: null, keywords: [] }
  }

  const prompt = `ë‹¤ìŒ IT ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: ${title}
ìš”ì•½: ${summary}

ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: ${availableCategories.join(', ')}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "category": "ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ 1ê°œ (ìœ„ ëª©ë¡ ì¤‘ì—ì„œë§Œ ì„ íƒ, ì—†ìœ¼ë©´ null)",
  "keywords": ["í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œ (í•œê¸€)"]
}

ê·œì¹™:
- categoryëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì— ìˆëŠ” ê²ƒë§Œ ì„ íƒ
- keywordsëŠ” ê¸°ìˆ  ìŠ¤íƒ, íšŒì‚¬ëª…, í•µì‹¬ ê°œë… ìœ„ì£¼ë¡œ
- í•œê¸€ë¡œ ì‘ì„±`

  try {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: 'claude-3-5-haiku-20241022',
        max_tokens: 500,
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
      }),
    })

    if (!response.ok) {
      throw new Error(`AI API failed: ${response.status}`)
    }

    const data = await response.json()
    const text = data.content[0].text

    // JSON íŒŒì‹± (ë°±í‹± ì œê±°)
    const jsonText = text.replace(/```json\n?|```\n?/g, '').trim()
    const result = JSON.parse(jsonText)

    return {
      category: result.category,
      keywords: result.keywords || [],
    }
  } catch (e) {
    console.error('AI analysis error:', e)
    return { category: null, keywords: [] }
  }
}
